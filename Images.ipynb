{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic \n",
    "\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Scikit-learn\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Deep Learning\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.keras import TqdmCallback\n",
    "import tensorflow as tf, re, math\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import *\n",
    "import efficientnet.tfkeras as efn\n",
    "from keras import layers\n",
    "from keras.applications import DenseNet121\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Visualization\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "from plotly.tools import FigureFactory as FF\n",
    "from plotly.offline import iplot\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Misc\n",
    "\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "import cufflinks\n",
    "import cv2 as cv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "import PIL\n",
    "from IPython.display import Image, display\n",
    "from keras.applications.vgg16 import VGG16,preprocess_input\n",
    "# Plotly for the interactive viewer (see last section)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, Model,load_model\n",
    "from keras.applications.vgg16 import VGG16,preprocess_input\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten,BatchNormalization,Activation\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import gc\n",
    "import skimage.io\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras import backend as K\n",
    "from livelossplot import PlotLossesKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-f938ff20bd1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbenchmark\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mseed_everything\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-f938ff20bd1f>\u001b[0m in \u001b[0;36mseed_everything\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# os.environ[\"PYTHONHASHSEED\"] = str(seed)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeterministic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed):\n",
    "    \"\"\"\n",
    "    Seeds basic parameters for reproductibility of results\n",
    "    \n",
    "    Arguments:\n",
    "        seed {int} -- Number of the seed\n",
    "    \"\"\"\n",
    "    # random.seed(seed)\n",
    "    # os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting file paths for our notebook:\n",
    "\n",
    "base_path = r'C:\\Users\\HIMANSHU\\Downloads\\Melanoma jpg'\n",
    "\n",
    "train_dir = r'C:\\Users\\HIMANSHU\\Downloads\\Melanoma jpg\\train'\n",
    "train_images = [f for f in listdir(train_img_path) if isfile(join(train_dir, f))]\n",
    "\n",
    "test_dir = r'C:\\Users\\HIMANSHU\\Downloads\\Melanoma jpg\\test'\n",
    "test_images = [f for f in listdir(test_img_path) if isfile(join(test_dir, f))]\n",
    "\n",
    "img_stats_path = r'C:\\Users\\HIMANSHU\\Downloads\\Melanoma Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading train and test data.\n",
    "\n",
    "train = pd.read_csv(os.path.join(base_path, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(base_path, 'test.csv'))\n",
    "sample = pd.read_csv(os.path.join(base_path, 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding exact number of Fraud and Non-fraud values\n",
    "# Fraud percentage is less than 1% of total transactions\n",
    "\n",
    "Malignant = train[train['target'] == 1]\n",
    "Benign = train[train['target'] == 0]\n",
    "\n",
    "print('Malignant shape: {}'.format(fraud.shape))\n",
    "print('Benign shape: {}'.format(normal.shape))\n",
    "print('Percentage of Malignant: {:.4f}%'.format(len(Benign)/(len(Malignant)+len(Benign)) * 100))\n",
    "print('Percentage of Malignant: {:.4f}%'.format(len(Malignant)/(len(Benign)+len(Malignant)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Class' is the target variable\n",
    "# It has two values counts - Fraud and Non-fraud\n",
    "# Plot showing the counts of both counts\n",
    "# Most of them are Non-fraud\n",
    "# This is an unbalanced dataset\n",
    "\n",
    "count_classes = pd.value_counts(train['target'], sort=True)\n",
    "count_classes.plot(kind='bar', rot=0)\n",
    "plt.title('Benign vs Malignant')\n",
    "plt.xticks(range(2), ['Benign', 'Malignant'])\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=train['anatom_site_general_challenge'].value_counts().index\n",
    "values=train['anatom_site_general_challenge'].value_counts().values\n",
    "fig = go.Figure(data=[go.Pie(labels=labels, values=values, textinfo='label+percent',\n",
    "                             insidetextorientation='radial'\n",
    "                            )])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=train['diagnosis'].value_counts().index[1:]\n",
    "values=train['diagnosis'].value_counts().values[1:]\n",
    "fig = go.Figure(data=[go.Pie(labels=labels, values=values, textinfo='label+percent',\n",
    "                             insidetextorientation='radial'\n",
    "                            )])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new=train.drop(labels=['image_name','patient_id','sex','age_approx','anatom_site_general_challenge','target'],axis=1)\n",
    "pd.crosstab(new['diagnosis'].values,new['benign_malignant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0=train[train['target']==0].sample(2000)\n",
    "df_1=train[train['target']==1]\n",
    "train=pd.concat([df_0,df_1])\n",
    "train=train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Benign Cases')\n",
    "# benign=[]\n",
    "# df_benign=df_0.sample(40)\n",
    "# df_benign=df_benign.reset_index()\n",
    "# for i in range(40):\n",
    "#     img = cv2.imread(str(train_dir + df_benign['image_name'].iloc[i]+'.jpg'))\n",
    "#     img = cv2.resize(img, (224,224))\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     img = img.astype(np.float32)/255.\n",
    "#     benign.append(img)\n",
    "# f, ax = plt.subplots(5,8, figsize=(10,8))\n",
    "# for i, img in enumerate(benign):\n",
    "#         ax[i//8, i%8].imshow(img)\n",
    "#         ax[i//8, i%8].axis('off')\n",
    "        \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(train_dir + df_benign['image_name'].iloc[0]+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, pandas as pd, matplotlib.pyplot as plt\n",
    "\n",
    "train = pd.read_csv(r'C:\\Users\\HIMANSHU\\Downloads\\Melanoma jpg\\train.csv')\n",
    "print('Examples WITH Melanoma')\n",
    "\n",
    "imgs = train.loc[train.target==1].sample(10).image_name.values\n",
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "for i,k in enumerate(imgs):\n",
    "    img = cv2.imread(r'C:\\Users\\HIMANSHU\\Downloads\\Melanoma jpg\\train\\%s.jpg'%k)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    plt.subplot(2,5,i+1); plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Examples WITHOUT Melanoma')\n",
    "imgs = train.loc[train.target==0].sample(10).image_name.values\n",
    "plt.figure(figsize=(20,8))\n",
    "for i,k in enumerate(imgs):\n",
    "    img = cv2.imread(r'C:\\Users\\HIMANSHU\\Downloads\\Melanoma jpg\\train\\%s.jpg'%k)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    plt.subplot(2,5,i+1); plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "data=[]\n",
    "for i in range(train.shape[0]):\n",
    "    data.append(train_dir + train['image_name'].iloc[i]+'.jpg')\n",
    "    labels.append(train['target'].iloc[i])\n",
    "df=pd.DataFrame(data)\n",
    "df.columns=['images']\n",
    "df['target']=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=[]\n",
    "for i in range(test.shape[0]):\n",
    "    test_data.append(test_dir + test['image_name'].iloc[i]+'.jpg')\n",
    "df_test=pd.DataFrame(test_data)\n",
    "df_test.columns=['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df['images'],df['target'], test_size=0.2, random_state=1234)\n",
    "\n",
    "train=pd.DataFrame(X_train)\n",
    "train.columns=['images']\n",
    "train['target']=y_train\n",
    "\n",
    "validation=pd.DataFrame(X_val)\n",
    "validation.columns=['images']\n",
    "validation['target']=y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll do some very basic preprocessing like\n",
    "\n",
    "normalizing\n",
    "reshaping\n",
    "augmentation(only for tarin data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,horizontal_flip=True)\n",
    "val_datagen=ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train,\n",
    "    x_col='images',\n",
    "    y_col='target',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    class_mode='raw')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "    validation,\n",
    "    x_col='images',\n",
    "    y_col='target',\n",
    "    target_size=(224, 224),\n",
    "    shuffle=False,\n",
    "    batch_size=8,\n",
    "    class_mode='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16_model( num_classes=None):\n",
    "\n",
    "    model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    x=Flatten()(model.output)\n",
    "    output=Dense(1,activation='sigmoid')(x) # because we have to predict the AUC\n",
    "    model=Model(model.input,output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "vgg_conv=vgg16_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(alpha=0.25,gamma=2.0):\n",
    "    def focal_crossentropy(y_true, y_pred):\n",
    "        bce = K.binary_crossentropy(y_true, y_pred)\n",
    "        \n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1.- K.epsilon())\n",
    "        p_t = (y_true*y_pred) + ((1-y_true)*(1-y_pred))\n",
    "        \n",
    "        alpha_factor = 1\n",
    "        modulating_factor = 1\n",
    "\n",
    "        alpha_factor = y_true*alpha + ((1-alpha)*(1-y_true))\n",
    "        modulating_factor = K.pow((1-p_t), gamma)\n",
    "\n",
    "        # compute the final loss and return\n",
    "        return K.mean(alpha_factor*modulating_factor*bce, axis=-1)\n",
    "    return focal_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=1e-5)\n",
    "vgg_conv.compile(loss=focal_loss(), metrics=[tf.keras.metrics.AUC()],optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 2\n",
    "batch_size=8\n",
    "nb_train_steps = train.shape[0]//batch_size\n",
    "nb_val_steps=validation.shape[0]//batch_size\n",
    "print(\"Number of training and validation steps: {} and {}\".format(nb_train_steps,nb_val_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb=[PlotLossesKeras()]\n",
    "vgg_conv.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_steps,\n",
    "    epochs=nb_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=cb,\n",
    "    validation_steps=nb_val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=[]\n",
    "for path in df_test['images']:\n",
    "    img=cv2.imread(str(path))\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)/255.\n",
    "    img=np.reshape(img,(1,224,224,3))\n",
    "    prediction=vgg_conv.predict(img)\n",
    "    target.append(prediction[0][0])\n",
    "\n",
    "submission['target']=target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
